{
  "hash": "a366d8b64e2927a074740f7239ad1276",
  "result": {
    "markdown": "---\ntitle: \"Revving Up: MPG Regression Unleashed through Deep Learning in PyTorch\"\nauthor: \"Lukman Aliyu Jibril\"\ndate: \"2023-08-09\"\ncategories: [deep learning,pytorch,regression,python]\n\n---\n\n# Introduction\n\nIn this article, we'll dive into the world of deep learning with PyTorch by constructing a multiple linear regression model to predict a vehicle's miles per gallon (MPG) based on various features. We'll explore the preprocessing steps, model architecture, training process, and evaluation of the model's performance.\n\n# Preparing the Data and Data Preprocessing\n\nOur journey begins by loading the auto MPG dataset, which contains information about vehicle characteristics and their corresponding MPG values. We'll focus on features like the number of cylinders, displacement, horsepower, weight, acceleration, manufacturing origin, and model year.\n\nTo ensure our data is suitable for training, we perform necessary preprocessing steps. We drop rows with missing values, standardize continuous features, and transform categorical features into one-hot encoded vectors.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport sklearn\nimport sklearn.model_selection\nimport torch\nimport torch.nn as nn\nfrom torch.nn.functional import one_hot\nfrom torch.utils.data import DataLoader,Dataset,TensorDataset\n# Load the dataset\nurl = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\ncolumn_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'Model Year', 'Origin']\n\ndf = pd.read_csv(url, names=column_names,\n                 na_values = \"?\", comment='\\t',\n                 sep=\" \", skipinitialspace=True)\n\n\n# Dropping rows with missing values\n\ndf = df.dropna().reset_index(drop=True)\n\n# Splitting the data into train and test sets\ndf_train, df_test = sklearn.model_selection.train_test_split(df, train_size=0.8, random_state=1)\n\n# Standardizing continuous features\nnumeric_column_names = ['Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration']\ntrain_stats = df_train.describe().transpose()\n\ndf_train_norm, df_test_norm = df_train.copy(), df_test.copy()\nfor col_name in numeric_column_names:\n    mean = train_stats.loc[col_name, 'mean']\n    std  = train_stats.loc[col_name, 'std']\n    df_train_norm[col_name] = (df_train_norm[col_name] - mean) / std\n    df_test_norm[col_name] = (df_test_norm[col_name] - mean) / std\n\n# Bucketing the model year categories\nboundaries = torch.tensor([73, 76, 79])\n \nv = torch.tensor(df_train_norm['Model Year'].values)\ndf_train_norm['Model Year Bucketed'] = torch.bucketize(v, boundaries, right=True)\n\nv = torch.tensor(df_test_norm['Model Year'].values)\ndf_test_norm['Model Year Bucketed'] = torch.bucketize(v, boundaries, right=True)\n\nnumeric_column_names.append('Model Year Bucketed')\n\n# One-hot encoding the origin feature\n\ntotal_origin = len(set(df_train_norm['Origin']))\n\norigin_encoded = one_hot(torch.from_numpy(df_train_norm['Origin'].values) % total_origin)\n\n# Creating the train and test feature and label tensors\n\nx_train_numeric = torch.tensor(df_train_norm[numeric_column_names].values)\nx_train = torch.cat([x_train_numeric, origin_encoded], 1).float()\n \norigin_encoded = one_hot(torch.from_numpy(df_test_norm['Origin'].values) % total_origin)\nx_test_numeric = torch.tensor(df_test_norm[numeric_column_names].values)\nx_test = torch.cat([x_test_numeric, origin_encoded], 1).float()\n\n\ny_train = torch.tensor(df_train_norm['MPG'].values).float()\ny_test = torch.tensor(df_test_norm['MPG'].values).float()\n\n# Creating a data loader to load the train dataset in batches\ntrain_ds = TensorDataset(x_train, y_train)\nbatch_size = 8\ntorch.manual_seed(1)\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True)\n```\n:::\n\n\n# Building the DNN Regression Model\n\nWith our data prepared, we move on to constructing our Deep Neural Network (DNN) regression model using PyTorch. This model will predict MPG values based on the vehicle's features.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Define the model architecture\nhidden_units = [8, 4]\ninput_size = x_train.shape[1]\n\nall_layers = []\nfor hidden_unit in hidden_units:\n    layer = nn.Linear(input_size, hidden_unit)\n    all_layers.append(layer)\n    all_layers.append(nn.ReLU())\n    input_size = hidden_unit\n\nall_layers.append(nn.Linear(hidden_units[-1], 1))\nmodel = nn.Sequential(*all_layers)\n\n# Define the loss function and optimizer\nloss_fn = nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n```\n:::\n\n\n# Training the Model\n\nIt's time to train our DNN regression model on the training data. We iterate through the data for a specified number of epochs, adjusting the model's weights to minimize the mean squared error loss.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nnum_epochs = 200\nlog_epochs = 20 \n\nfor epoch in range(num_epochs):\n    loss_hist_train = 0\n    for x_batch, y_batch in train_dl:\n        pred = model(x_batch)[:, 0]\n        loss = loss_fn(pred, y_batch)\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        loss_hist_train += loss.item()\n    if epoch % log_epochs == 0:\n        print(f'Epoch {epoch}  Loss {loss_hist_train/len(train_dl):.4f}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 0  Loss 530.7308\nEpoch 20  Loss 7.8103\nEpoch 40  Loss 7.7546\nEpoch 60  Loss 6.9081\nEpoch 80  Loss 6.8482\nEpoch 100  Loss 6.7144\nEpoch 120  Loss 6.4509\nEpoch 140  Loss 7.1134\nEpoch 160  Loss 6.4428\nEpoch 180  Loss 6.2078\n```\n:::\n:::\n\n\n# Evaluating the Model\n\nOnce the model is trained, we assess its performance on the test dataset. This helps us understand how well the model generalizes to new, unseen data.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nwith torch.no_grad():\n    pred = model(x_test.float())[:, 0]\n    loss = loss_fn(pred, y_test)\n    mae = nn.L1Loss()(pred, y_test)\n    print(f'Test MSE: {loss.item():.4f}')\n    print(f'Test MAE: {mae.item():.4f}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTest MSE: 13.1923\nTest MAE: 2.6507\n```\n:::\n:::\n\n\nSeeing the good metrics, let's confirm by plotting the actual and predicted values\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n# Plotting actual vs. predicted MPG values\nplt.figure(figsize=(10, 6))\nplt.scatter(y_test, pred, color='blue', label='Predicted')\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2, linestyle='--', label='Perfect Prediction')\nplt.xlabel('Actual MPG')\nplt.ylabel('Predicted MPG')\nplt.title('Actual vs. Predicted MPG Values')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-6-output-1.png){width=816 height=523}\n:::\n:::\n\n\n# Conclusion\n\nOur DNN regression model demonstrates promising results in predicting MPG values based on vehicle features. By carefully preprocessing the data, constructing an appropriate model architecture, and iteratively training the model, we achieve a model that generalizes reasonably well to new data. This article serves as a starting point for your journey into deep learning with PyTorch, enabling you to build more advanced models and tackle a variety of data analysis challenges.\n\n",
    "supporting": [
      "index_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}