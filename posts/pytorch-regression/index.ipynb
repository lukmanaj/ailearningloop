{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Revving Up: MPG Regression Unleashed through Deep Learning in PyTorch\"\n",
        "author: \"Lukman Aliyu Jibril\"\n",
        "date: \"2023-08-09\"\n",
        "categories: [deep learning,pytorch,regression,python]\n",
        "---"
      ],
      "id": "965bd3f8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction\n",
        "\n",
        "In this article, we'll dive into the world of deep learning with PyTorch by constructing a simple linear regression model to predict a vehicle's miles per gallon (MPG) based on various features. We'll explore the preprocessing steps, model architecture, training process, and evaluation of the model's performance.\n",
        "\n",
        "# Preparing the Data\n",
        "\n",
        "Our journey begins by loading the auto MPG dataset, which contains information about vehicle characteristics and their corresponding MPG values. We'll focus on features like the number of cylinders, displacement, horsepower, weight, acceleration, manufacturing origin, and model year.\n"
      ],
      "id": "12ec5e56"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn\n",
        "import sklearn.model_selection\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import one_hot\n",
        "from torch.utils.data import DataLoader,Dataset,TensorDataset"
      ],
      "id": "4dbb020b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load the dataset\n",
        "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
        "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'Model Year', 'Origin']\n",
        "\n",
        "df = pd.read_csv(url, names=column_names,\n",
        "                 na_values = \"?\", comment='\\t',\n",
        "                 sep=\" \", skipinitialspace=True)\n",
        "df.tail()\n",
        " ```\n",
        "\n",
        "\n",
        "                \n",
        "# Data Preprocessing\n",
        "\n",
        "To ensure our data is suitable for training, we perform necessary preprocessing steps. We drop rows with missing values, standardize continuous features, and transform categorical features into one-hot encoded vectors.\n"
      ],
      "id": "685fc0d5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Dropping rows with missing values\n",
        "\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "# Splitting the data into train and test sets\n",
        "df_train, df_test = sklearn.model_selection.train_test_split(df, train_size=0.8, random_state=1)\n",
        "\n",
        "# Standardizing continuous features\n",
        "numeric_column_names = ['Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration']\n",
        "train_stats = df_train.describe().transpose()\n",
        "\n",
        "df_train_norm, df_test_norm = df_train.copy(), df_test.copy()\n",
        "for col_name in numeric_column_names:\n",
        "    mean = train_stats.loc[col_name, 'mean']\n",
        "    std  = train_stats.loc[col_name, 'std']\n",
        "    df_train_norm[col_name] = (df_train_norm[col_name] - mean) / std\n",
        "    df_test_norm[col_name] = (df_test_norm[col_name] - mean) / std\n",
        "\n",
        "# Bucketing the model year categories\n",
        "boundaries = torch.tensor([73, 76, 79])\n",
        " \n",
        "v = torch.tensor(df_train_norm['Model Year'].values)\n",
        "df_train_norm['Model Year Bucketed'] = torch.bucketize(v, boundaries, right=True)\n",
        "\n",
        "v = torch.tensor(df_test_norm['Model Year'].values)\n",
        "df_test_norm['Model Year Bucketed'] = torch.bucketize(v, boundaries, right=True)\n",
        "\n",
        "numeric_column_names.append('Model Year Bucketed')\n",
        "\n",
        "# One-hot encoding the origin feature\n",
        "\n",
        "total_origin = len(set(df_train_norm['Origin']))\n",
        "\n",
        "origin_encoded = one_hot(torch.from_numpy(df_train_norm['Origin'].values) % total_origin)\n",
        "\n",
        "# Creating the train and test feature and label tensors\n",
        "\n",
        "x_train_numeric = torch.tensor(df_train_norm[numeric_column_names].values)\n",
        "x_train = torch.cat([x_train_numeric, origin_encoded], 1).float()\n",
        " \n",
        "origin_encoded = one_hot(torch.from_numpy(df_test_norm['Origin'].values) % total_origin)\n",
        "x_test_numeric = torch.tensor(df_test_norm[numeric_column_names].values)\n",
        "x_test = torch.cat([x_test_numeric, origin_encoded], 1).float()\n",
        "\n",
        "\n",
        "y_train = torch.tensor(df_train_norm['MPG'].values).float()\n",
        "y_test = torch.tensor(df_test_norm['MPG'].values).float()\n",
        "\n",
        "# Creating a data loader to load the train dataset in batches\n",
        "train_ds = TensorDataset(x_train, y_train)\n",
        "batch_size = 8\n",
        "torch.manual_seed(1)\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
      ],
      "id": "e2ea1381",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Building the DNN Regression Model\n",
        "\n",
        "With our data prepared, we move on to constructing our Deep Neural Network (DNN) regression model using PyTorch. This model will predict MPG values based on the vehicle's features.\n"
      ],
      "id": "39bfab6b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define the model architecture\n",
        "hidden_units = [8, 4]\n",
        "input_size = x_train.shape[1]\n",
        "\n",
        "all_layers = []\n",
        "for hidden_unit in hidden_units:\n",
        "    layer = nn.Linear(input_size, hidden_unit)\n",
        "    all_layers.append(layer)\n",
        "    all_layers.append(nn.ReLU())\n",
        "    input_size = hidden_unit\n",
        "\n",
        "all_layers.append(nn.Linear(hidden_units[-1], 1))\n",
        "model = nn.Sequential(*all_layers)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
      ],
      "id": "36b31888",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training the Model\n",
        "\n",
        "It's time to train our DNN regression model on the training data. We iterate through the data for a specified number of epochs, adjusting the model's weights to minimize the mean squared error loss.\n"
      ],
      "id": "dfb6a479"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "num_epochs = 200\n",
        "log_epochs = 20 \n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    loss_hist_train = 0\n",
        "    for x_batch, y_batch in train_dl:\n",
        "        pred = model(x_batch)[:, 0]\n",
        "        loss = loss_fn(pred, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        loss_hist_train += loss.item()\n",
        "    if epoch % log_epochs == 0:\n",
        "        print(f'Epoch {epoch}  Loss {loss_hist_train/len(train_dl):.4f}')"
      ],
      "id": "b3c389fd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluating the Model\n",
        "\n",
        "Once the model is trained, we assess its performance on the test dataset. This helps us understand how well the model generalizes to new, unseen data.\n"
      ],
      "id": "1240cdb2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "with torch.no_grad():\n",
        "    pred = model(x_test.float())[:, 0]\n",
        "    loss = loss_fn(pred, y_test)\n",
        "    mae = nn.L1Loss()(pred, y_test)\n",
        "    print(f'Test MSE: {loss.item():.4f}')\n",
        "    print(f'Test MAE: {mae.item():.4f}')"
      ],
      "id": "d4ca2a87",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Seeing the good metrics, let's confirm by plotting the actual and predicted values\n"
      ],
      "id": "b3c1eda3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plotting actual vs. predicted MPG values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, pred, color='blue', label='Predicted')\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2, linestyle='--', label='Perfect Prediction')\n",
        "plt.xlabel('Actual MPG')\n",
        "plt.ylabel('Predicted MPG')\n",
        "plt.title('Actual vs. Predicted MPG Values')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "076860a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion\n",
        "\n",
        "Our DNN regression model demonstrates promising results in predicting MPG values based on vehicle features. By carefully preprocessing the data, constructing an appropriate model architecture, and iteratively training the model, we achieve a model that generalizes reasonably well to new data. This article serves as a starting point for your journey into deep learning with PyTorch, enabling you to build more advanced models and tackle a variety of data analysis challenges."
      ],
      "id": "47fec5f0"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}